{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd0f7af-8298-4992-b291-655f7adba094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Step 1: Generate example data\n",
    "num_train_examples = 20000\n",
    "sequence_length = 8\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 25\n",
    "val_split = 0.2\n",
    "\n",
    "rng = np.random.default_rng(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c821fb62-e725-493d-9bc9-3d4ee5d3a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random frequencies for sine waves\n",
    "# we'll use 1.0 as the maximum Nyquist frequency and 0 = constant\n",
    "frequencies = rng.uniform(0.02, 0.2, size=num_train_examples)\n",
    "phase_offsets = rng.uniform(0.0, 2*np.pi, size=num_train_examples)\n",
    "sequences = np.zeros((num_train_examples, sequence_length))\n",
    "\n",
    "# Generate sine waves\n",
    "for i in range(num_train_examples):\n",
    "    sequences[i] = np.sin(2*np.pi*frequencies[i]* np.arange(sequence_length) + phase_offsets[i])\n",
    "\n",
    "# Split sequences into input (first <sequence_length-1> elements) and labels (sequence_length>'th element)\n",
    "x_train = sequences[:, :sequence_length-1]\n",
    "y_train = sequences[:, sequence_length-1]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8d7ea-ed4b-4533-a7e6-6e17c16fe47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818b915a-f2ce-40c0-8e09-daacba9c2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "  layers.InputLayer(input_shape=x_train.shape[1:]), \n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(1)  # Single neuron for regression\n",
    "])\n",
    "input_shape = x_train.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "steps_per_epoch = int((1.0-val_split)*num_train_examples / batch_size)\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(1e-2, steps_per_epoch*num_epochs)\n",
    "  \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), # use tf.keras.optimizers.Adam on Intel / NVidia GPU\n",
    "              loss='mean_squared_error'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521118b4-7bbd-450a-b158-29a2cb4ae15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2979 - val_loss: 0.1519\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0328\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - val_loss: 0.0231\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0162 - val_loss: 0.0019\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - val_loss: 0.0041\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0028\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0014\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0116 - val_loss: 0.0033\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0115 - val_loss: 0.0031\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 - val_loss: 0.0014\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0106 - val_loss: 0.0013\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 3.4000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0016\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0021\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 4.8230e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 4.4797e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0011\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0113 - val_loss: 0.0011\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0095 - val_loss: 2.9136e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 4.0915e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 2.2734e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - val_loss: 1.8719e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 8.1987e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 - val_loss: 9.7424e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 8.8235e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_hist = model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773c4120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TF Version: 2.18.0\n",
      "Input: [-0.0064896  -0.87153519 -0.85803593  0.02040035  0.8782722   0.850808\n",
      " -0.03430716]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\super\\AppData\\Local\\Temp\\tmpzef4jtdt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\super\\AppData\\Local\\Temp\\tmpzef4jtdt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\super\\AppData\\Local\\Temp\\tmpzef4jtdt'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 7), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2628912920912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931292496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931300768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931302352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931296192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931298480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931303584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931304288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931388688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931304640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931300240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931387984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931303936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2628931392032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as new_sin_predictor.tflite\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using TF Version: {tf.version.VERSION}\")\n",
    "\n",
    "choice = x_train[np.random.randint(0, x_train.shape[0])]\n",
    "print(f\"Input: {choice}\")\n",
    "\n",
    "def representative_dataset():\n",
    "    # Generate synthetic sine wave data matching training distribution\n",
    "    for _ in range(100):\n",
    "        yield [x_train[np.random.randint(0, x_train.shape[0])].astype(np.float32)]\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('new_sin_predictor.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"Model saved as new_sin_predictor.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e5fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Scale: 0.007843123748898506 | Input Zero Point: 0\n",
      "Output Scale: 0.007811177987605333 | Output Zero Point: 0\n",
      "Raw Input: [[ 0.86234552  0.93621396  0.31616721 -0.53822045 -0.9936829  -0.7126346\n",
      "   0.09661345]]\n",
      "Quantized Input: [[ 109  119   40  -68 -126  -90   12]]\n",
      "Quantized Prediction: [[104]]\n",
      "Dequantized Prediction: [[0.8123625]]\n",
      "Arena Size: 5260 bytes\n"
     ]
    }
   ],
   "source": [
    "# Test in Python\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get quantization parameters\n",
    "input_scale = input_details[0]['quantization'][0]\n",
    "input_zero_point = input_details[0]['quantization'][1]\n",
    "\n",
    "print(f\"Input Scale: {input_scale} | Input Zero Point: {input_zero_point}\")\n",
    "print(f\"Output Scale: {output_details[0]['quantization'][0]} | Output Zero Point: {output_details[0]['quantization'][1]}\")\n",
    "\n",
    "# Scale and quantize input\n",
    "raw_input = x_train[0].reshape(1, -1)\n",
    "quantized_input = raw_input / input_scale + input_zero_point\n",
    "input_data = quantized_input.astype(np.int8)\n",
    "print(\"Raw Input:\", raw_input)\n",
    "print(\"Quantized Input:\", input_data)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Quantized Prediction:\", output)\n",
    "\n",
    "# Dequantize output\n",
    "output_scale = output_details[0]['quantization'][0]\n",
    "output_zero_point = output_details[0]['quantization'][1]\n",
    "dequantized_output = (output.astype(np.float32) - output_zero_point) * output_scale\n",
    "print(\"Dequantized Prediction:\", dequantized_output)\n",
    "\n",
    "size = 0\n",
    "for tensor in interpreter.get_tensor_details():\n",
    "    match tensor['dtype']:\n",
    "        case np.int8:\n",
    "            size += np.prod(tensor['shape'])\n",
    "        case np.float32:\n",
    "            size += np.prod(tensor['shape']) * 4\n",
    "        case np.int32:\n",
    "            size += np.prod(tensor['shape']) * 4\n",
    "        case _:\n",
    "            raise ValueError(f\"Unsupported data type: {tensor['dtype']}\")\n",
    "    \n",
    "            \n",
    "\n",
    "print(f\"Arena Size: {size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a36081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xxd\n",
    "xxd.binary_to_c_array('new_sin_predictor.tflite', 'new_sin_predictor_data.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f10c7-bb9e-4604-863c-428d8cbb5a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
